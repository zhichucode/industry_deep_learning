{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics\n",
    "import scipy.spatial as sp\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import scipy.io"
   ],
   "metadata": {
    "id": "Lt1BAloNsGZQ"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle"
   ],
   "metadata": {
    "id": "nH5CKrKIA094"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default='NSL')\n",
    "parser.add_argument('--beta', type=float, default=0.1)\n",
    "parser.add_argument(\"--dev\", help=\"device\", default=\"cuda:0\")\n",
    "parser.add_argument(\"--epochs\", type=int, help=\"number of epochs for ae\", default=5000)\n",
    "parser.add_argument(\"--lr\", type=float, help=\"learning rate\", default=1e-2)\n",
    "parser.add_argument(\"--memlen\", type=int, help=\"size of memory\", default=2048)\n",
    "parser.add_argument(\"--seed\", type=int, help=\"random seed\", default=0)\n",
    "#args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()"
   ],
   "metadata": {
    "id": "xy7aXikysK2T"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "args"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlOaMExFtilj",
    "outputId": "d8518db5-fa75-4496-b41d-7b66f20665b3"
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Namespace(dataset='NSL', beta=0.1, dev='cuda:0', epochs=5000, lr=0.01, memlen=2048, seed=0)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(args.seed)\n",
    "nfile = None\n",
    "lfile = None"
   ],
   "metadata": {
    "id": "zfD2f7fmMYxq"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title unused codes\n",
    "# # set the data file and the label file\n",
    "# if args.dataset == 'NSL':\n",
    "#     nfile = 'data/nsl.txt'\n",
    "#     lfile = 'data/nsllabel.txt'\n",
    "# elif args.dataset == 'KDD':\n",
    "#     nfile = '../data/kdd.txt'\n",
    "#     lfile = '../data/kddlabel.txt'\n",
    "# elif args.dataset == 'UNSW':\n",
    "#     nfile = '../data/unsw.txt'\n",
    "#     lfile = '../data/unswlabel.txt'\n",
    "# elif args.dataset == 'DOS':\n",
    "#     nfile = '../data/dos.txt'\n",
    "#     lfile = '../data/doslabel.txt'\n",
    "# elif args.dataset == 'XYZ':\n",
    "#     nfile = '../data/xyz.txt'\n",
    "#     lfile = '../data/xyzlabel.txt'\n",
    "# else:\n",
    "#     df = scipy.io.loadmat('../data/'+args.dataset+\".mat\")\n",
    "#     numeric = torch.FloatTensor(df['X'])\n",
    "#     labels = (df['y']).astype(float).reshape(-1)\n",
    "\n"
   ],
   "metadata": {
    "id": "I2AdoCKWsVFH"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda:0')\n",
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BnvZMF4mMkFn",
    "outputId": "fb1224c5-8486-41bb-c490-c4802879c00c"
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MemStream Model"
   ],
   "metadata": {
    "id": "iNCx_HWysgzJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MemStream(nn.Module):\n",
    "    def __init__(self, in_dim, params):\n",
    "        super(MemStream, self).__init__()\n",
    "        self.params = params\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = in_dim*2\n",
    "        self.memory_len = params['memory_len']\n",
    "        self.max_thres = torch.tensor(params['beta']).to(device)\n",
    "\n",
    "        self.memory = torch.randn(self.memory_len, self.out_dim).to(device)\n",
    "\n",
    "        self.mem_data = torch.randn(self.memory_len, self.in_dim).to(device)\n",
    "\n",
    "        self.memory.requires_grad = False # this attribute of tensor\n",
    "        self.mem_data.requires_grad = False\n",
    "\n",
    "        self.batch_size = params['memory_len']\n",
    "\n",
    "        self.num_mem_update = 0\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, self.out_dim),\n",
    "            nn.Tanh(),\n",
    "        ).to(device)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.out_dim, self.in_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        self.clock = 0\n",
    "        self.last_update = -1\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=params['lr'])\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "        self.count = 0\n",
    "\n",
    "    \n",
    "    def train_autoencoder(self, data, epochs):\n",
    "        self.mean, self.std = self.mem_data.mean(0), self.mem_data.std(0)\n",
    "        new = (data - self.mean) / self.std # z-score\n",
    "        new[:, self.std == 0] = 0 # let new=0 where self.mem_data.std(0)==0, because 0 cannot be devided\n",
    "        new = Variable(new)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.decoder(self.encoder(new + 0.001*torch.randn_like(new).to(device)))\n",
    "            loss = self.loss_fn(output, new)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "\n",
    "    def update_memory(self, output_loss, encoder_output, data):\n",
    "        if output_loss <= self.max_thres: # when output_loss is less than self.max_thres\n",
    "            least_used_pos = self.count % self.memory_len\n",
    "            self.memory[least_used_pos] = encoder_output\n",
    "            self.mem_data[least_used_pos] = data\n",
    "            # update the self.mean and self.std\n",
    "            self.mean, self.std = self.mem_data.mean(0), self.mem_data.std(0) \n",
    "            self.count += 1\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    def initialize_memory(self, x):\n",
    "        mean, std = model.mem_data.mean(0), model.mem_data.std(0)\n",
    "        new = (x - mean) / std\n",
    "        new[:, std == 0] = 0\n",
    "        self.memory = self.encoder(new) \n",
    "        self.memory.requires_grad = False\n",
    "        self.mem_data = x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # new is the z_score\n",
    "        new = (x - self.mean) / self.std\n",
    "        new[:, self.std == 0] = 0\n",
    "\n",
    "        encoder_output = self.encoder(new) \n",
    "        loss_values = torch.norm(self.memory - encoder_output, dim=1, p=1).min()\n",
    "        self.update_memory(loss_values, encoder_output, x)\n",
    "        return loss_values"
   ],
   "metadata": {
    "id": "uDHSR7A0sZ3t"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "A6nOVrptsk8j"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# print(f'args.dataset: {args.dataset}')\n",
    "# if args.dataset in ['KDD', 'NSL', 'UNSW', 'DOS']:\n",
    "#     print(f'nifle: {nfile}; lfile: {lfile}')\n",
    "#     numeric = torch.FloatTensor(np.loadtxt(nfile, delimiter = ','))\n",
    "#     labels = np.loadtxt(lfile, delimiter=',')\n",
    "\n",
    "# if args.dataset == 'KDD':\n",
    "#     labels = 1 - labels"
   ],
   "metadata": {
    "id": "5F743om2vD7l"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# numeric = torch.FloatTensor(np.loadtxt('data/nsl.txt', delimiter=','))\n",
    "# numeric.shape"
   ],
   "metadata": {
    "id": "4AnADAxeRbt2"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as lf:\n",
    "        load_data = pickle.load(lf)\n",
    "    return load_data"
   ],
   "metadata": {
    "id": "7SeW-Vc0Ngzp"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "numeric = torch.FloatTensor(load_pickle('pickle/y.pickle').numpy())\n",
    "numeric.shape\n",
    "numeric = numeric.reshape((numeric.shape[0]), 1)\n",
    "numeric.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUYI3DpOPdmH",
    "outputId": "3c7b8b7c-2c14-4c04-9d38-a9e921f6688d"
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 10:27:25.742900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 10:27:25.835000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-08 10:27:25.835015: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-08 10:27:25.836690: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([4618332, 1])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(args.seed)\n",
    "N = args.memlen #2048\n",
    "params = {\n",
    "          'beta': args.beta, \n",
    "          'memory_len': N, \n",
    "          'batch_size':1, \n",
    "          'lr':args.lr\n",
    "         }"
   ],
   "metadata": {
    "id": "caBqbCk2z0OU"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#model = MemStream(numeric[0].shape[0],params).to(device)\n",
    "model = MemStream(numeric[0].shape[0],params).to(device)\n",
    "model"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZqgB9MG0Jil",
    "outputId": "6d4d332d-afd8-44ed-cd3b-91eec5514b2e"
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzh/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": "MemStream(\n  (encoder): Sequential(\n    (0): Linear(in_features=1, out_features=2, bias=True)\n    (1): Tanh()\n  )\n  (decoder): Sequential(\n    (0): Linear(in_features=2, out_features=1, bias=True)\n  )\n  (loss_fn): MSELoss()\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = params['batch_size']\n",
    "print(args.dataset, args.beta, args.memlen, args.lr, args.epochs)\n",
    "data_loader = DataLoader(numeric, batch_size=batch_size)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYzUkBHX06oe",
    "outputId": "16481549-6421-484b-97ed-4d7924f867e5"
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSL 0.1 2048 0.01 5000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#init_data = numeric[labels == 0][:N].to(device)\n",
    "init_data = numeric[:][:N].to(device)\n",
    "init_data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQTemVGk1E5d",
    "outputId": "dade5773-9c11-48af-fdf9-fbd21c0701d7"
   },
   "execution_count": 17,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/IPython/core/formatters.py:707\u001B[0m, in \u001B[0;36mPlainTextFormatter.__call__\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    700\u001B[0m stream \u001B[38;5;241m=\u001B[39m StringIO()\n\u001B[1;32m    701\u001B[0m printer \u001B[38;5;241m=\u001B[39m pretty\u001B[38;5;241m.\u001B[39mRepresentationPrinter(stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[1;32m    702\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_width, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnewline,\n\u001B[1;32m    703\u001B[0m     max_seq_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_seq_length,\n\u001B[1;32m    704\u001B[0m     singleton_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msingleton_printers,\n\u001B[1;32m    705\u001B[0m     type_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtype_printers,\n\u001B[1;32m    706\u001B[0m     deferred_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeferred_printers)\n\u001B[0;32m--> 707\u001B[0m \u001B[43mprinter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpretty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    708\u001B[0m printer\u001B[38;5;241m.\u001B[39mflush()\n\u001B[1;32m    709\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stream\u001B[38;5;241m.\u001B[39mgetvalue()\n",
      "File \u001B[0;32m~/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/IPython/lib/pretty.py:410\u001B[0m, in \u001B[0;36mRepresentationPrinter.pretty\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    407\u001B[0m                         \u001B[38;5;28;01mreturn\u001B[39;00m meth(obj, \u001B[38;5;28mself\u001B[39m, cycle)\n\u001B[1;32m    408\u001B[0m                 \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mobject\u001B[39m \\\n\u001B[1;32m    409\u001B[0m                         \u001B[38;5;129;01mand\u001B[39;00m callable(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__repr__\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m--> 410\u001B[0m                     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_repr_pprint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcycle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _default_pprint(obj, \u001B[38;5;28mself\u001B[39m, cycle)\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/IPython/lib/pretty.py:778\u001B[0m, in \u001B[0;36m_repr_pprint\u001B[0;34m(obj, p, cycle)\u001B[0m\n\u001B[1;32m    776\u001B[0m \u001B[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001B[39;00m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;66;03m# Find newlines and replace them with p.break_()\u001B[39;00m\n\u001B[0;32m--> 778\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mrepr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    779\u001B[0m lines \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39msplitlines()\n\u001B[1;32m    780\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m p\u001B[38;5;241m.\u001B[39mgroup():\n",
      "File \u001B[0;32m~/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/torch/_tensor.py:338\u001B[0m, in \u001B[0;36mTensor.__repr__\u001B[0;34m(self, tensor_contents)\u001B[0m\n\u001B[1;32m    335\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__repr__\u001B[39m, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    336\u001B[0m                                  tensor_contents\u001B[38;5;241m=\u001B[39mtensor_contents)\n\u001B[1;32m    337\u001B[0m \u001B[38;5;66;03m# All strings are unicode in Python 3.\u001B[39;00m\n\u001B[0;32m--> 338\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tensor_str\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_str\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor_contents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_contents\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/torch/_tensor_str.py:481\u001B[0m, in \u001B[0;36m_str\u001B[0;34m(self, tensor_contents)\u001B[0m\n\u001B[1;32m    479\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_str\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m, tensor_contents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 481\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_str_intern\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor_contents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_contents\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/torch/_tensor_str.py:447\u001B[0m, in \u001B[0;36m_str_intern\u001B[0;34m(inp, tensor_contents)\u001B[0m\n\u001B[1;32m    445\u001B[0m                     tensor_str \u001B[38;5;241m=\u001B[39m _tensor_str(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_dense(), indent)\n\u001B[1;32m    446\u001B[0m                 \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 447\u001B[0m                     tensor_str \u001B[38;5;241m=\u001B[39m \u001B[43m_tensor_str\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayout \u001B[38;5;241m!=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstrided:\n\u001B[1;32m    450\u001B[0m     suffixes\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayout=\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayout))\n",
      "File \u001B[0;32m~/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/torch/_tensor_str.py:270\u001B[0m, in \u001B[0;36m_tensor_str\u001B[0;34m(self, indent)\u001B[0m\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _tensor_str_with_formatter(\u001B[38;5;28mself\u001B[39m, indent, summarize, real_formatter, imag_formatter)\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 270\u001B[0m     formatter \u001B[38;5;241m=\u001B[39m _Formatter(\u001B[43mget_summarized_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m summarize \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _tensor_str_with_formatter(\u001B[38;5;28mself\u001B[39m, indent, summarize, formatter)\n",
      "File \u001B[0;32m~/anaconda3/envs/industry_DL2/lib/python3.9/site-packages/torch/_tensor_str.py:302\u001B[0m, in \u001B[0;36mget_summarized_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    299\u001B[0m     start \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, PRINT_OPTS\u001B[38;5;241m.\u001B[39medgeitems)]\n\u001B[1;32m    300\u001B[0m     end \u001B[38;5;241m=\u001B[39m ([\u001B[38;5;28mself\u001B[39m[i]\n\u001B[1;32m    301\u001B[0m            \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m PRINT_OPTS\u001B[38;5;241m.\u001B[39medgeitems, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m))])\n\u001B[0;32m--> 302\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mget_summarized_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mstack([get_summarized_data(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m])\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.mem_data = init_data\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "model.train_autoencoder(Variable(init_data).to(device), epochs=args.epochs)\n",
    "torch.set_grad_enabled(False)\n",
    "model.initialize_memory(Variable(init_data[:N]))"
   ],
   "metadata": {
    "id": "BCHyFGPN1Teh"
   },
   "execution_count": 18,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mmem_data \u001B[38;5;241m=\u001B[39m init_data\n\u001B[1;32m      3\u001B[0m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_autoencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mVariable\u001B[49m\u001B[43m(\u001B[49m\u001B[43minit_data\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39minitialize_memory(Variable(init_data[:N]))\n",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36mMemStream.train_autoencoder\u001B[0;34m(self, data, epochs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_autoencoder\u001B[39m(\u001B[38;5;28mself\u001B[39m, data, epochs):\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmean, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmem_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmem_data\u001B[38;5;241m.\u001B[39mstd(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     41\u001B[0m     new \u001B[38;5;241m=\u001B[39m (data \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmean) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstd \u001B[38;5;66;03m# z-score\u001B[39;00m\n\u001B[1;32m     42\u001B[0m     new[:, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstd \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;66;03m# let new=0 where self.mem_data.std(0)==0, because 0 cannot be devided\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.set_grad_enabled(False)\n",
    "model.initialize_memory(Variable(init_data[:N]))"
   ],
   "metadata": {
    "id": "Kbs2HmKu10uJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "err = []\n",
    "for data in tqdm(data_loader):\n",
    "    output = model(data.to(device))\n",
    "    err.append(output)"
   ],
   "metadata": {
    "id": "Bvp8hM2L2DHX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0366bbef-a7d6-418f-f6c0-fa8900b7f5c8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "err"
   ],
   "metadata": {
    "id": "vR5XC2lC2Fo3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozKISSMRru-Z"
   },
   "outputs": [],
   "source": [
    "scores = np.array([i.cpu() for i in err])\n",
    "auc = metrics.roc_auc_score(labels, scores)\n",
    "print(\"ROC-AUC\", auc)"
   ]
  }
 ]
}
